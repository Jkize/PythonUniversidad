{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "readJSON=open(\"News_Category_Dataset_v2.json\", \"r\", encoding=\"utf-8\")\n",
    "arrayJSON=readJSON.readlines()\n",
    "writer= open(\"categories.json\",\"w+\") #Escribir archivo\n",
    "writer.write(\"[\")\n",
    "for strJSON in arrayJSON:\n",
    "    dataStore = json.loads(strJSON)\n",
    "    if (dataStore[\"category\"]== 'ENTERTAINMENT' or dataStore[\"category\"]=='POLITICS' or dataStore[\"category\"]=='TECH' ):\n",
    "        writer.write(json.dumps(dataStore)+\",\")\n",
    "writer.write(\"{}]\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "readJSON=open(\"categories.json\", \"r\", encoding=\"utf-8\")\n",
    "arrayCategories=json.loads(readJSON.read())\n",
    "del arrayCategories[len(arrayCategories)-1] #Eliminar el vacio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53681"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(arrayCategories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función entrenamiento y retorna el Accurancy Score, Precision Score, Recall Score y F1 Score\n",
    "\n",
    "def PIA(mss,label):\n",
    "    X_train, X_test, y_train, y_test=train_test_split(mss, label, random_state=1)\n",
    "    count_vector=CountVectorizer()\n",
    "    training_data=count_vector.fit_transform(X_train)\n",
    "    training_data = count_vector.fit_transform(X_train)\n",
    "    testing_data = count_vector.transform(X_test)\n",
    "    naive_bayes = MultinomialNB()\n",
    "    naive_bayes.fit(training_data, y_train)\n",
    "    predictions = naive_bayes.predict(testing_data)\n",
    "    matConfu=confusion_matrix(y_test, predictions)  \n",
    "    print(matConfu) \n",
    "    vec=[accuracy_score(y_test, predictions),precision_score(y_test, predictions,average='macro'),recall_score(y_test, predictions,average='macro'),f1_score(y_test, predictions,average='macro')]\n",
    "    return vec\n",
    "    #return metricasMatrizConfusion(matConfu)\n",
    "\n",
    "#Fila Real Columna Predicción\n",
    "def accurancy(mat):\n",
    "    acc=0\n",
    "    diagonal=0\n",
    "    total=0 \n",
    "    for i in range(len(mat)):\n",
    "        for j in range((len(mat))):\n",
    "            if i==j: \n",
    "                diagonal+=mat[i][j]\n",
    "            total+=mat[i][j]\n",
    "    acc=diagonal/total\n",
    "    return acc\n",
    "\n",
    "#Fila Real Columna Predicción. Total de verdadero la cat A sobre el total de reales de A\n",
    "def recall(mat):    \n",
    "    mat=np.array(mat)\n",
    "    return (mat[0][0])/(mat.sum(axis=1)[0])\n",
    "    \n",
    "\n",
    "#Fila Real Columna Predicción. Total de verdadero la cat A sobre el total de prediciones de A\n",
    "def precision(mat):\n",
    "    mat=np.array(mat)\n",
    "    return (mat[0][0])/(mat.sum(axis=0)[0])\n",
    "\n",
    "def F1Score(r,p):\n",
    "    return (2*r*p)/(r+p)\n",
    "\n",
    "def metricasMatrizConfusion(mat):\n",
    "    vec=[accurancy(mat),precision(mat),recall(mat),precision(mat)]\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión headline/short_description/headline + short_description \n",
      "[[3636  374    5]\n",
      " [ 267 7912   12]\n",
      " [ 101  221  192]]\n",
      "[[2491 1519    5]\n",
      " [ 512 7663   16]\n",
      " [ 135  289   90]]\n",
      "[[3689  321    5]\n",
      " [ 258 7922   11]\n",
      " [ 104  207  203]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head line</th>\n",
       "      <th>short_description</th>\n",
       "      <th>head line + short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accurancy Score</th>\n",
       "      <td>0.922956</td>\n",
       "      <td>0.805346</td>\n",
       "      <td>0.928774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Score</th>\n",
       "      <td>0.908092</td>\n",
       "      <td>0.793818</td>\n",
       "      <td>0.910639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Score</th>\n",
       "      <td>0.905604</td>\n",
       "      <td>0.620423</td>\n",
       "      <td>0.918804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.908092</td>\n",
       "      <td>0.793818</td>\n",
       "      <td>0.910639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 head line  short_description  head line + short_description\n",
       "Accurancy Score   0.922956           0.805346                       0.928774\n",
       "Precision Score   0.908092           0.793818                       0.910639\n",
       "Recall Score      0.905604           0.620423                       0.918804\n",
       "F1 Score          0.908092           0.793818                       0.910639"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Matriz de confusión headline/short_description/headline + short_description \")\n",
    "vecHL=PIA(df[\"headline\"],df[\"category\"])\n",
    "vecSH=PIA(df[\"short_description\"],df[\"category\"])\n",
    "vecHLSH=PIA(df[\"short_description\"]+df[\"headline\"],df[\"category\"])\n",
    "newDf = pd.DataFrame({\"head line\":vecHL, \"short_description\":vecSH, \"head line + short_description\":vecHLSH },index=[\"Accurancy Score\",\"Precision Score\",\"Recall Score\",\"F1 Score\"])\n",
    "newDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En todas sus métricas usando para entrenamiento \"short_description\" es menor a \"head line\" y a\n",
    "\"head line + short_description\". Y a su vez usando \"head line + short_description\" es mayor en todas sus metricas a \"head line\". \n",
    "\n",
    "Por lo tanto, entre más información se sabe acerca de la categorias \"ENTERTAINMENT, POLITICS, y TECH\" la predicción será mayor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python37064bit77c32bfef69240b193135a62ae515774"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
