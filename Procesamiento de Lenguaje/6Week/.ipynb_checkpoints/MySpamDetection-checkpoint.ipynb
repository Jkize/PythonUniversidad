{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                        sms_message\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Dataset from - https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
    "df = pd.read_table('smsspamcollection/SMSSpamCollection',\n",
    "                   sep='\\t', \n",
    "                   header=None, \n",
    "                   names=['label', 'sms_message'])\n",
    "# imprima las primeras 5 filas\n",
    "df.head()\n",
    "#Cambiamos las etiquetas texutales por etiquetas numericas, esto es una buena practica cuando se construyen modelo supervisados\n",
    "df['label'] = df.label.map({'ham':0, 'spam':1})\n",
    "print(df.shape)\n",
    "df.head() # returns (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contSpam</th>\n",
       "      <th>contHam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amore</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buffet</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bugis</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cine</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>florida</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidden</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>royal</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tog</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOTAL DOC</th>\n",
       "      <td>565</td>\n",
       "      <td>3614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7232 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           contSpam  contHam\n",
       "word                        \n",
       "amore             0        1\n",
       "available         2       13\n",
       "buffet            0        2\n",
       "bugis             0        6\n",
       "cine              0        7\n",
       "...             ...      ...\n",
       "florida           0        1\n",
       "hidden            0        1\n",
       "royal             0        1\n",
       "tog               0        1\n",
       "TOTAL DOC       565     3614\n",
       "\n",
       "[7232 rows x 2 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cuenta cuantas veces la palabra es spam o ham en todo el documento\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vector = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "datos={\"contSpam\":[],\"contHam\":[]}\n",
    "mapa=dict() #Mapa para guardar el index de la palabra que va en datos\n",
    "\n",
    "tam=len(df)\n",
    "tam75=int(tam*0.75) \n",
    "\n",
    "totalSpam=0\n",
    "totalHam=0\n",
    "for i in range(tam75):\n",
    "    valSpam=0\n",
    "    valHam=0\n",
    "    if( df[\"label\"][i]==1):\n",
    "        valSpam=1\n",
    "        totalSpam+=1\n",
    "    else:\n",
    "        valHam=1\n",
    "        totalHam+=1 \n",
    "    listWord=[]\n",
    "    \n",
    "    try: \n",
    "        count_vector.fit([df[\"sms_message\"][i]])\n",
    "        listWord=count_vector.get_feature_names()\n",
    "    except ValueError:\n",
    "        rellenar=0\n",
    "        \n",
    "    for word in listWord:\n",
    "        if word in mapa:\n",
    "            #Verifica para que la palabra tomada no este más de 1 vez en el documento\n",
    "            if i not in mapa[word][\"docs\"]:\n",
    "                mapa[word][\"docs\"][i]=1                \n",
    "                pos=mapa[word][\"pos\"]\n",
    "                datos[\"contSpam\"][pos]+=valSpam\n",
    "                datos[\"contHam\"][pos]+=valHam\n",
    "        else:\n",
    "            pos=len(datos[\"contSpam\"])\n",
    "            mapa[word]={\"pos\":pos,\"docs\":{i:1}}\n",
    "            datos[\"contSpam\"].append(valSpam)\n",
    "            datos[\"contHam\"].append(valHam)\n",
    "\n",
    "#Agregar número total de documentos de stop words y demás\n",
    "mapa[\"TOTAL DOC\"]=len(datos[\"contSpam\"])\n",
    "datos[\"contSpam\"].append(totalSpam)\n",
    "datos[\"contHam\"].append(totalHam)             \n",
    "newDf = pd.DataFrame(datos, columns= ['contSpam', 'contHam'], index=list(mapa))\n",
    "newDf.index.name=\"word\"\n",
    "newDf.to_csv (r'conteoSpamHam.csv', index = True, header=True) #Don't forget to add '.csv' at the end of the path\n",
    "newDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se crea el archivo probabilidades de que la palabra sea spam o ham\n",
    "tamano=len(newDf)  \n",
    "newDf['contSpam'] = newDf['contSpam'].astype(float)\n",
    "newDf['contHam'] = newDf['contHam'].astype(float)\n",
    "\n",
    "for indice_fila,fila  in newDf.iterrows():\n",
    "    if(indice_fila!=\"TOTAL DOC\"):\n",
    "        newDf[\"contSpam\"][indice_fila]=newDf[\"contSpam\"][indice_fila]/newDf[\"contSpam\"][\"TOTAL DOC\"]\n",
    "        newDf[\"contHam\"][indice_fila]=newDf[\"contHam\"][indice_fila]/newDf[\"contHam\"][\"TOTAL DOC\"]\n",
    "\n",
    "totalDocs=newDf[\"contHam\"][\"TOTAL DOC\"]+newDf[\"contSpam\"][\"TOTAL DOC\"]\n",
    "newDf[\"contHam\"][\"TOTAL DOC\"]=newDf[\"contHam\"][\"TOTAL DOC\"]/totalDocs\n",
    "newDf[\"contSpam\"][\"TOTAL DOC\"]=newDf[\"contSpam\"][\"TOTAL DOC\"]/totalDocs\n",
    "newDf.rename(columns={\"contSpam\": \"probSpam\", \"contHam\": \"probHam\"},inplace = True) \n",
    "newDf.to_csv (r'probSpamHam.csv',index = True, header=True) #Don't forget to add '.csv' at the end of the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probSpam</th>\n",
       "      <th>probHam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amore</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available</th>\n",
       "      <td>0.00354</td>\n",
       "      <td>0.003597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buffet</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bugis</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.001660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cine</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.001937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>florida</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidden</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>royal</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tog</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOTAL DOC</th>\n",
       "      <td>0.13520</td>\n",
       "      <td>0.864800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7232 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           probSpam   probHam\n",
       "word                         \n",
       "amore       0.00000  0.000277\n",
       "available   0.00354  0.003597\n",
       "buffet      0.00000  0.000553\n",
       "bugis       0.00000  0.001660\n",
       "cine        0.00000  0.001937\n",
       "...             ...       ...\n",
       "florida     0.00000  0.000277\n",
       "hidden      0.00000  0.000277\n",
       "royal       0.00000  0.000277\n",
       "tog         0.00000  0.000277\n",
       "TOTAL DOC   0.13520  0.864800\n",
       "\n",
       "[7232 rows x 2 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probDataset=pd.read_csv(\"probSpamHam.csv\",index_col=\"word\") \n",
    "probDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[173, 17], [9, 1194]]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matriz confusion  row=(Spam,Ham) col=(Spam,Ham)\n",
    "matrizConfusion=[[0, 0],[0 ,0]]\n",
    "for i in range(tam75,tam):\n",
    "    is_Spam=False\n",
    "    is_Ham=False\n",
    "    if( df[\"label\"][i]==1):\n",
    "        is_Spam=True \n",
    "    else:\n",
    "        is_Ham=True\n",
    "    \n",
    "    listWord=[]\n",
    "    try: \n",
    "        count_vector.fit([df[\"sms_message\"][i]])\n",
    "        listWord=count_vector.get_feature_names()\n",
    "    except ValueError:\n",
    "        rellenar=0\n",
    "    pSpam=None\n",
    "    pHam=None\n",
    "    for word in listWord:\n",
    "        if word in probDataset[\"probSpam\"]:\n",
    "            if pSpam == None:\n",
    "                pSpam=probDataset[\"probSpam\"][word]\n",
    "                pHam=probDataset[\"probHam\"][word]\n",
    "            else:\n",
    "                pSpam*=probDataset[\"probSpam\"][word]\n",
    "                pHam*=probDataset[\"probHam\"][word]\n",
    "                \n",
    "    if pSpam==None:\n",
    "        pSpam=0\n",
    "        pHam=0\n",
    "    \n",
    "   \n",
    "    if pSpam != pHam:\n",
    "        pSpam*=probDataset[\"probSpam\"][\"TOTAL DOC\"]\n",
    "        pHam*=probDataset[\"probHam\"][\"TOTAL DOC\"]\n",
    "        if pSpam>pHam:\n",
    "            if is_Spam:\n",
    "                matrizConfusion[0][0]+=1\n",
    "            else:\n",
    "                matrizConfusion[0][1]+=1\n",
    "        else:\n",
    "            if is_Ham:\n",
    "                matrizConfusion[1][1]+=1\n",
    "            else:\n",
    "                matrizConfusion[1][0]+=1\n",
    "    else:\n",
    "        if is_Spam:\n",
    "            matrizConfusion[0][0]+=1\n",
    "        else:\n",
    "            matrizConfusion[1][1]+=1\n",
    "matrizConfusion    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam</th>\n",
       "      <th>Ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Spam</th>\n",
       "      <td>173</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ham</th>\n",
       "      <td>9</td>\n",
       "      <td>1194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Spam   Ham\n",
       "Spam   173    17\n",
       "Ham      9  1194"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMatrizConfunsion= pd.DataFrame(matrizConfusion , columns= ['Spam', 'Ham'], index=[\"Spam\",\"Ham\"])\n",
    "dfMatrizConfunsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conclusión: La diferencia con respecto al F1 Score dio 2%, esto quiere decir que la eficiencia de scikit-learn es mucho mejor prediciendo debido a principalmente lo siguiente:  \n",
      " hubo un 3% de diferencia con respecto al Recall queriendose decir que no se trajo todos los relevantes y un 2% en la precisión.  \n",
      "  1. Cuando la probabilidad era igual a que  fuera SPAM o HAM \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hecho por mi</th>\n",
       "      <th>scikit-learn</th>\n",
       "      <th>Diferencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accurancy Score</th>\n",
       "      <td>0.981335</td>\n",
       "      <td>0.988514</td>\n",
       "      <td>0.007179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Score</th>\n",
       "      <td>0.950549</td>\n",
       "      <td>0.972067</td>\n",
       "      <td>0.021518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Score</th>\n",
       "      <td>0.910526</td>\n",
       "      <td>0.940541</td>\n",
       "      <td>0.030014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.930108</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.025936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Hecho por mi  scikit-learn  Diferencia\n",
       "Accurancy Score      0.981335      0.988514    0.007179\n",
       "Precision Score      0.950549      0.972067    0.021518\n",
       "Recall Score         0.910526      0.940541    0.030014\n",
       "F1 Score             0.930108      0.956044    0.025936"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP=matrizConfusion[0][0]\n",
    "FN=matrizConfusion[0][1]\n",
    "FP=matrizConfusion[1][0]\n",
    "TN=matrizConfusion[1][1]\n",
    "\n",
    "aS_IA=0.9885139985642498\n",
    "p_IA=0.9720670391061452\n",
    "r_IA=0.9405405405405406\n",
    "F1_IA=0.9560439560439562\n",
    "\n",
    "aS=(TP+TN)/(TP+TN+FP+FN)\n",
    "r=(TP)/(TP+FN)\n",
    "p=(TP)/(TP+FP)\n",
    "F1=(2*recall*precision)/(recall+precision)\n",
    "\n",
    "matrizFinal=[[aS,aS_IA, abs(aS-aS_IA) ],[p,p_IA,abs(p-p_IA)],[r,r_IA,abs(r-r_IA)],[F1,F1_IA,abs(F1-F1_IA)]]\n",
    "dfMatrizFinal= pd.DataFrame(matrizFinal , columns= ['Hecho por mi', 'scikit-learn',\"Diferencia\"], index=[\"Accurancy Score\",\"Precision Score\",\"Recall Score\",\"F1 Score\"])\n",
    "print(\"Conclusión: La diferencia con respecto al F1 Score dio 2%, esto quiere decir que la eficiencia de scikit-learn es mucho mejor prediciendo debido a principalmente lo siguiente: \",\n",
    "      \"\\n hubo un 3% de diferencia con respecto al Recall queriendo decir que no se trajo todos los relevantes y un 2% en la precisión. \"\n",
    "      ,\"\\n \"\n",
    "      ,\"1. Cuando la probabilidad era igual a que  fuera SPAM o HAM \")\n",
    "dfMatrizFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4179\n"
     ]
    }
   ],
   "source": [
    "print(tam75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python37064bit77c32bfef69240b193135a62ae515774"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
