{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TALLER PREPARCICAL\n",
    "BY: JHOAN SAAVEDRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim import similarities\n",
    "from smart_open import smart_open\n",
    "from xml.dom import minidom\n",
    "from os import listdir \n",
    "import re\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leer documentos\n",
    "stop = open(\"stopWord.txt\", \"r\", encoding=\"utf-8\")\n",
    "stop_words=stop.readlines()\n",
    "docs=open(\"text.txt\", \"r\", encoding=\"utf-8\")\n",
    "docs=docs.readlines()\n",
    "steamer=[ [\"gato\",\"gata\",\"gatos\"], [\"pata\",\"patas\"],\n",
    "        [\"pato\",\"patos\"],[\"pluma\",\"plumas\"], [\"ganar\",\"ganan\",\"gana\"] ,[\"garrapata\",\"garrapatas\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_StopWords(arrayText):\n",
    "    newArrayText=[]  \n",
    "    for txt in arrayText:\n",
    "        txt=txt+\"\\n\"\n",
    "        if txt not in stop_words:\n",
    "            txt=txt.rstrip(\"\\n\")\n",
    "            bol=True\n",
    "            for arr in steamer:\n",
    "                if txt in arr:\n",
    "                    bol=False\n",
    "                    newArrayText.append(arr[0])\n",
    "                    break\n",
    "            if(bol):\n",
    "                newArrayText.append(txt.rstrip(\"\\n\"))              \n",
    "    return newArrayText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procesamiento de un texto utilizando las funciones de Gensim\n",
    "#Y quitando simbolos\n",
    "def process(text):     \n",
    "    stem=re.findall(r'[\\w]+', text.lower() ) \n",
    "    newStem=remove_StopWords(stem) \n",
    "    return newStem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear Diccionario\n",
    "docDict=[]\n",
    "for txt in docs:\n",
    "    docDict.append(process(txt))\n",
    "dictionary=corpora.Dictionary(docDict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clase para crear corpus teniendo encuenta el diccionario\n",
    "class MyCorpus(object):\n",
    "    def __iter__(self):\n",
    "        for txt in docs:\n",
    "            yield dictionary.doc2bow(process(txt))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_memory=MyCorpus()\n",
    "#Guardar Corpus\n",
    "corpora.MmCorpus.serialize('corpus.mm',corpus_memory)\n",
    "#Cargar Corpus\n",
    "corpus=corpora.MmCorpus('corpus.mm')\n",
    "#Crear tfidf del corpus\n",
    "tfidf=models.TfidfModel(corpus)\n",
    "#Guardar tfidf\n",
    "#tfidf.save(\"tfidfCorpus.mm\") \n",
    "#Matrix de similidad\n",
    "index=similarities.MatrixSimilarity(tfidf[corpus]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ninguna', 'palabra', 'común']\n",
      "Top 5 documentos de la query 1\n",
      "El documento 1 tiene una similitud de 0.0000 \n",
      "El documento 2 tiene una similitud de 0.0000 \n",
      "El documento 3 tiene una similitud de 0.0000 \n",
      "El documento 4 tiene una similitud de 0.0000 \n",
      "El documento 5 tiene una similitud de 0.0000 \n",
      "\n",
      "['gato', 'pato', 'ganar', 'dinero', 'garrapata', 'pata', 'pluma', 'cola']\n",
      "Top 5 documentos de la query 2\n",
      "El documento 4 tiene una similitud de 0.9252 \n",
      "El documento 1 tiene una similitud de 0.4221 \n",
      "El documento 2 tiene una similitud de 0.4221 \n",
      "El documento 3 tiene una similitud de 0.2477 \n",
      "El documento 5 tiene una similitud de 0.0559 \n",
      "\n",
      "['cucaracha', 'pluma']\n",
      "Top 5 documentos de la query 3\n",
      "El documento 5 tiene una similitud de 0.8283 \n",
      "El documento 3 tiene una similitud de 0.2281 \n",
      "El documento 4 tiene una similitud de 0.1772 \n",
      "El documento 1 tiene una similitud de 0.0000 \n",
      "El documento 2 tiene una similitud de 0.0000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#PUNTO 3 CALCULAR SIMILITUD\n",
    "\n",
    "QUERIES=[\"No tengo ninguna palabra en común\",\n",
    "        \"La gata y el pato ganan dinero con las garrapatas de las patas y las plumas de la cola\",\n",
    "        \"La cucaracha no tiene plumas\"]\n",
    "n=1\n",
    "arraySortSims=[]\n",
    "for query in QUERIES:    \n",
    "    query_doc_bow=dictionary.doc2bow(process(query))\n",
    "    print(process(query))\n",
    "    sims=list(index[tfidf[query_doc_bow]])\n",
    "    listSims=list((enumerate(sims))) \n",
    "    sortSims=sorted(listSims,key=lambda pair: pair[1],reverse=True)\n",
    "    arraySortSims.append(sortSims)\n",
    "    print(\"Top 5 documentos de la query\",n)\n",
    "    for dat in sortSims:\n",
    "        id=dat[0]+1\n",
    "        print(\"El documento {} tiene una similitud de {:.4f} \".format(id,dat[1]))\n",
    "    n+=1\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#4[20p] Considere como documentos relevantes para el query (ii) D1, D2, D3, D4, y D5 mientras que para el query (i) no existe ningún documento relevante.\n",
    "Calcule la P@1,R@1,F1@1,P@5,R@5,F1@5 para cada query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1]\n",
      "[0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "relevanteQ2=[1,1,1,1,1]\n",
    "relevanteQ1=[0,0,0,0,0]\n",
    "print(relevanteQ2)\n",
    "print(relevanteQ1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para llenar la matriz del query con Revelante\n",
    "# P@K y R@K\n",
    "def rPK_RK(arrayQuery):\n",
    "    mQuery=[]\n",
    "    relevantes=sum(arrayQuery)\n",
    "    n=0\n",
    "    for i in arrayQuery: \n",
    "        mQuery.append([])\n",
    "        mQuery[n].append(i)# Relevante\n",
    "        if(n==0):\n",
    "            mQuery[n].append(i) #Relevante inicial acumulativo          \n",
    "        else:\n",
    "            mQuery[n].append(i+mQuery[n-1][1]) #Relevante acumulativo\n",
    "        mQuery[n].append( mQuery[n][1]/relevantes ) # R@K\n",
    "        mQuery[n].append(mQuery[n][1]/(n+1) ) # P@K\n",
    "        n+=1\n",
    "    return mQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  1.  0.2 1. ]\n",
      " [1.  2.  0.4 1. ]\n",
      " [1.  3.  0.6 1. ]\n",
      " [1.  4.  0.8 1. ]\n",
      " [1.  5.  1.  1. ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mQuery2=np.array(rPK_RK(relevanteQ2))  \n",
    "print(mQuery2,\"\\n\")\n",
    "#mQuery1=np.array(rPK_RK(relevanteQ1))  \n",
    "#print(mQuery1,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuestas para el Query 2\n",
      "P@1= 1.0000 R@1= 0.2000 F@1 0.3333 \n",
      "P@5= 1.0000 R@5= 1.0000 F@5 1.0000 \n",
      "\n",
      "Respuestas para el Query 1\n",
      "P@1= 0.0000 R@1= 0.0000 F@1 0.0000 \n",
      "P@5= 0.0000 R@5= 0.0000 F@5 0.0000 \n"
     ]
    }
   ],
   "source": [
    "print(\"Respuestas para el Query 2\")\n",
    "print(\"P@1= {:.4f} R@1= {:.4f} F@1 {:.4f} \".format(mQuery2[0][3],mQuery2[0][2],(2*mQuery2[0][3]*mQuery2[0][2])/(mQuery2[0][3]+mQuery2[0][2]) ))\n",
    "print(\"P@5= {:.4f} R@5= {:.4f} F@5 {:.4f} \".format(mQuery2[4][3],mQuery2[4][2], (2*mQuery2[4][3]*mQuery2[4][2])/(mQuery2[4][3]+mQuery2[4][2])  ))\n",
    "print(\"\")\n",
    "print(\"Respuestas para el Query 1\")\n",
    "print(\"P@1= {:.4f} R@1= {:.4f} F@1 {:.4f} \".format(0.0,0.0,0.0))\n",
    "print(\"P@5= {:.4f} R@5= {:.4f} F@5 {:.4f} \".format(0.0,0.0,0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfGainDCGI(query_rel):\n",
    "    mat=[]\n",
    "    n=0\n",
    "    for i in query_rel:\n",
    "        mat.append([])\n",
    "        mat[n].append(i) #REl_i\n",
    "        mat[n].append(1/(math.log(max(n+1,2), 2))) #discount_factor\n",
    "        mat[n].append(i*mat[n][1])\n",
    "        if(n==0):\n",
    "            mat[n].append(mat[n][2]) #DCG_i\n",
    "        else:\n",
    "            mat[n].append(mat[n][2]+mat[n-1][3]) #DCG_i\n",
    "        n+=1\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NDCG(matQ,matQN):\n",
    "    row=len(matQ)\n",
    "    col=len(matQ[0])\n",
    "    return matQ[row-1][col-1]/matQN[row-1][col-1] "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#5[20p] Suponga que existe una escala de relevancia D1:4, D2:3, D3:3, D4:5, D5:2 para el query (iii). En qué orden deben presentarse los documentos para obtener el máximo y mínimo valor de DCG. Calculelos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 5, 4, 3]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "escalaR={ 1:4,2:3,3:3,4:5,5:2 } #Query III\n",
    "vectorEscala=[] \n",
    "sortSims=arraySortSims[2]\n",
    "for a in sortSims:\n",
    "    id=a[0]+1\n",
    "    if id in escalaR:\n",
    "        vectorEscala.append(escalaR[id])\n",
    "    else:\n",
    "        vectorEscala.append(0)\n",
    "vectorEscala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dcg del query 3 es:  11.446678442077467\n",
      "El dcg normalizado del query 3 del query 3 es: 13.254142376861159\n"
     ]
    }
   ],
   "source": [
    "dcg=np.array(dfGainDCGI( vectorEscala ))\n",
    "dcgN=np.array(dfGainDCGI( sorted( vectorEscala ,reverse=True)))\n",
    "#print(dcg,\"\\n\",\"\\n\",dcgN)\n",
    "print(\"El dcg del query 3 es: \",dcg[4][3])\n",
    "print(\"El dcg normalizado del query 3 del query 3 es:\",dcgN[4][3])\n",
    "#ndcg=NDCG(dcg,dcgN) \n",
    "#print(\"NDCG: De los 10 documentos es:\",ndcg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python37064bit77c32bfef69240b193135a62ae515774"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
