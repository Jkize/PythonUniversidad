{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TALLER PREPARCICAL\n",
    "BY: JHON BUESAQUILLO - JUAN PABLO HERNÁNDEZ - JHOAN SAAVEDRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim import similarities\n",
    "from smart_open import smart_open\n",
    "from xml.dom import minidom\n",
    "from os import listdir \n",
    "import re\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leer documentos\n",
    "stop = open(\"stopWord.txt\", \"r\", encoding=\"utf-8\")\n",
    "stop_words=stop.readlines()\n",
    "docs=open(\"text.txt\", \"r\", encoding=\"utf-8\")\n",
    "docs=docs.readlines()\n",
    "steamer=[ [\"estudiar\",\"estudiamos\",\"estudio\"], [\"similitud\",\"similitudes\"],\n",
    "        [\"usa\",\"usando\"],[\"modelo\",\"modelos\",\"modelamiento\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_StopWords(arrayText):\n",
    "    newArrayText=[]  \n",
    "    for txt in arrayText:\n",
    "        txt=txt+\"\\n\"\n",
    "        if txt not in stop_words:\n",
    "            txt=txt.rstrip(\"\\n\")\n",
    "            bol=True\n",
    "            for arr in steamer:\n",
    "                if txt in arr:\n",
    "                    bol=False\n",
    "                    newArrayText.append(arr[0])\n",
    "                    break\n",
    "            if(bol):\n",
    "                newArrayText.append(txt.rstrip(\"\\n\"))              \n",
    "    return newArrayText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procesamiento de un texto utilizando las funciones de Gensim\n",
    "#Y quitando simbolos\n",
    "def process(text):     \n",
    "    stem=re.findall(r'[\\w]+', text.lower() ) \n",
    "    newStem=remove_StopWords(stem) \n",
    "    return newStem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear Diccionario\n",
    "docDict=[]\n",
    "for txt in docs:\n",
    "    docDict.append(process(txt))\n",
    "dictionary=corpora.Dictionary(docDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clase para crear corpus teniendo encuenta el diccionario\n",
    "class MyCorpus(object):\n",
    "    def __iter__(self):\n",
    "        for txt in docs:\n",
    "            yield dictionary.doc2bow(process(txt))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_memory=MyCorpus()\n",
    "#Guardar Corpus\n",
    "corpora.MmCorpus.serialize('corpus.mm',corpus_memory)\n",
    "#Cargar Corpus\n",
    "corpus=corpora.MmCorpus('corpus.mm')\n",
    "#Crear tfidf del corpus\n",
    "tfidf=models.TfidfModel(corpus)\n",
    "#Guardar tfidf\n",
    "#tfidf.save(\"tfidfCorpus.mm\") \n",
    "index=similarities.MatrixSimilarity(tfidf[corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top documentos\n",
      "El documento 3 tiene una similitud de 0.5809503793716431 \n",
      "El documento 4 tiene una similitud de 0.2632814347743988 \n",
      "El documento 1 tiene una similitud de 0.2360454499721527 \n",
      "El documento 7 tiene una similitud de 0.21359914541244507 \n",
      "El documento 6 tiene una similitud de 0.19569028913974762 \n",
      "El documento 9 tiene una similitud de 0.12573328614234924 \n",
      "El documento 2 tiene una similitud de 0.0 \n",
      "El documento 5 tiene una similitud de 0.0 \n",
      "El documento 8 tiene una similitud de 0.0 \n",
      "El documento 10 tiene una similitud de 0.0 \n"
     ]
    }
   ],
   "source": [
    "#PUNTO 3 CALCULAR SIMILITUD\n",
    "query=\"modelo de bolsa de estudio\"\n",
    "query_doc_bow=dictionary.doc2bow(process(query))  \n",
    "sims=list(index[tfidf[query_doc_bow]])\n",
    "listSims=list((enumerate(sims))) \n",
    "sortSims=sorted(listSims,key=lambda pair: pair[1],reverse=True)\n",
    "print(\"Top documentos\")\n",
    "for dat in sortSims:\n",
    "    id=dat[0]+1\n",
    "    print(\"El documento {} tiene una similitud de {} \".format(id,dat[1]))\n",
    " "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#4 Si los documentos relevantes para el query anterior son D6, D7, D10 y D1, calcule P@5, R@5, F1@5, P@3, R@3 y F1@3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 1, 1, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "#Relevantes\n",
    "relevantesQuery=[6,7,10,1] #Del query\n",
    "relevante=[]\n",
    "for a in sortSims:\n",
    "    id=a[0]+1\n",
    "    if id in relevantesQuery:\n",
    "        relevante.append(1)\n",
    "    else:\n",
    "        relevante.append(0)\n",
    "print(relevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para llenar la matriz del query con Revelante\n",
    "# P@K y R@K\n",
    "def rPK_RK(arrayQuery):\n",
    "    mQuery=[]\n",
    "    relevantes=sum(arrayQuery)\n",
    "    n=0\n",
    "    for i in arrayQuery: \n",
    "        mQuery.append([])\n",
    "        mQuery[n].append(i)# Relevante\n",
    "        if(n==0):\n",
    "            mQuery[n].append(i) #Relevante inicial acumulativo          \n",
    "        else:\n",
    "            mQuery[n].append(i+mQuery[n-1][1]) #Relevante acumulativo\n",
    "        mQuery[n].append( mQuery[n][1]/relevantes ) # R@K\n",
    "        mQuery[n].append(mQuery[n][1]/(n+1) ) # P@K\n",
    "        n+=1\n",
    "    return mQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1\n",
      " isRelevant sumRelevant  R@K       P@K \n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [1.         1.         0.25       0.33333333]\n",
      " [1.         2.         0.5        0.5       ]\n",
      " [1.         3.         0.75       0.6       ]\n",
      " [0.         3.         0.75       0.5       ]\n",
      " [0.         3.         0.75       0.42857143]\n",
      " [0.         3.         0.75       0.375     ]\n",
      " [0.         3.         0.75       0.33333333]\n",
      " [1.         4.         1.         0.4       ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mQuery1=np.array(rPK_RK(relevante))\n",
    "print(\"Query 1\\n\",\"isRelevant sumRelevant  R@K       P@K \")\n",
    "print(mQuery1,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuestas\n",
      "P@5= 0.6 R@5= 0.75 F@5 0.6666666666666665 \n",
      "P@3= 0.3333333333333333 R@3= 0.25 F@3 0.28571428571428575 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Respuestas\")\n",
    "print(\"P@5= {} R@5= {} F@5 {} \".format(mQuery1[4][3],mQuery1[4][2], (2*mQuery1[4][3]*mQuery1[4][2])/(mQuery1[4][3]+mQuery1[4][2])  ))\n",
    "print(\"P@3= {} R@3= {} F@3 {} \".format(mQuery1[2][3],mQuery1[2][2],(2*mQuery1[2][3]*mQuery1[2][2])/(mQuery1[2][3]+mQuery1[2][2]) ))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#5 Suponga que existe una escala de relevancia D6:4, D7:3, D10:3, D1:5 (otros documentos relevancia de 0). Calcule el NDCG para los primeros 10 documentos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfGainDCGI(query_rel):\n",
    "    mat=[]\n",
    "    n=0\n",
    "    for i in query_rel:\n",
    "        mat.append([])\n",
    "        mat[n].append(i) #REl_i\n",
    "        mat[n].append(1/(math.log(max(n+1,2), 2))) #discount_factor\n",
    "        mat[n].append(i*mat[n][1])\n",
    "        if(n==0):\n",
    "            mat[n].append(mat[n][2]) #DCG_i\n",
    "        else:\n",
    "            mat[n].append(mat[n][2]+mat[n-1][3]) #DCG_i\n",
    "        n+=1\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NDCG(matQ,matQN):\n",
    "    row=len(matQ)\n",
    "    col=len(matQ[0])\n",
    "    return matQ[row-1][col-1]/matQN[row-1][col-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 5, 3, 4, 0, 0, 0, 0, 3]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "escalaR={ 6:4,7:3,10:3,1:5 }\n",
    "vectorEscala=[] \n",
    "for a in sortSims:\n",
    "    id=a[0]+1\n",
    "    if id in escalaR:\n",
    "        vectorEscala.append(escalaR[id])\n",
    "    else:\n",
    "        vectorEscala.append(0)\n",
    "vectorEscala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: De los 10 documentos es: 0.5874742831480317\n"
     ]
    }
   ],
   "source": [
    "dcg=np.array(dfGainDCGI( vectorEscala ))\n",
    "dcgN=np.array(dfGainDCGI( sorted( vectorEscala ,reverse=True)))\n",
    "#print(dcg,\"\\n\",\"\\n\",dcgN)\n",
    "\n",
    "ndcg=NDCG(dcg,dcgN)\n",
    "print(\"NDCG: De los 10 documentos es:\",ndcg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python37064bit77c32bfef69240b193135a62ae515774"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
